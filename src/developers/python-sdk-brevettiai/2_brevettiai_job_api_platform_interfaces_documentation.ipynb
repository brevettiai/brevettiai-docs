{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqbkhGASC9i6"
   },
   "source": [
    "---\n",
    "description: This section documents through examples the simple usage the job api's to access a model training job's artifacts, datasets and lots of other stuff  in a development context\n",
    "---\n",
    "# Introduction to Brevetti AI Job API\n",
    "The brevettiai Job API is your execution context when running a job on the platform. A job being defined as a model training process, or the process of creating a test report. The brevettiai package is a lightweight api for interfacing with the cloud ressources.\n",
    "\n",
    "It provides a python interface to the website, and keeps track of the resources you have available there, and parsing of input in the form of settings to your code.\n",
    "\n",
    "![Job API](https://gblobscdn.gitbook.com/assets%2F-LY12YhLSCDWlqNaQqWT%2Fsync%2F5bd21284c912c0d6b26828d4d36358c7445f44fd.png)\n",
    "\n",
    "From the platform, a job \\(model or test report\\) is an input configuration with a storage space attached. The storage space freely available to use by the job, but following a few conventions, allows the platform to parse specific content for display on the model page.\n",
    "\n",
    "This section explores its usage from the perspective of a developer training models on his/her own computer.\n",
    "Except for the initialization of the environment, all of the code is transferrable to a docker containerized deployment of model training on the platform.\n",
    "\n",
    "Use help(CriterionConfig) to get an overview over available methods.\n",
    "\n",
    "## Job lifecycle\n",
    "\n",
    "### Start\n",
    "\n",
    "To begin executing a job you first need do get an execution context, thereby start the job. To do this you run the application.init function. This returns a CriterionConfig object to you, which is your configuration for the job.\n",
    "\n",
    "```text\n",
    "from brevettiai.platform import Job\n",
    "job = Job.init()\n",
    "```\n",
    "\n",
    "This command expects the job GUID and API key as arguments via argv or parameters on the function.\n",
    "\n",
    "Settings may be added to the job by creating a settings definition \\(schema\\). This schema is parsed to generate UI on the platform, and parsed by the config object, to use specific modules. Pass a `path` to a schema or a `SchemaBuilder` object to the `init` function to use apply it to the configuration.\n",
    "\n",
    "### Execute\n",
    "\n",
    "Run your application code, and use tooling for integration with the platform features.\n",
    "\n",
    "Add custom output metrics to your job.\n",
    "\n",
    "```text\n",
    "print(f\"Uploading metrics and outputs to {job.host_name}\")\n",
    "job.add_output_metric(\"My custom metric\", 277)\n",
    "job.upload_job_output()\n",
    "```\n",
    "\n",
    "### Complete\n",
    "\n",
    "On completion, complete the job on the platform to signal that you are done with the job. This action is performed by calling `complete_job` on the config object you got when starting the job. You can additionally call upload\\_job\\_output, to serialize the configuration object and upload metrics added during the training. \n",
    "\n",
    "```text\n",
    "job.complete_job(path_to_artifact_with_model_archive)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzEXlRHhEavu"
   },
   "source": [
    "# Brevetti AI package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7MCqSgiEY83"
   },
   "outputs": [],
   "source": [
    "pip install brevettiai[tfa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6uIDiTBC9i8"
   },
   "outputs": [],
   "source": [
    "# Imports and setup to avoid extensive verboisty\n",
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig()\n",
    "log.root.setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3faNHKZdTb0"
   },
   "source": [
    "# API:  BrevettiAI Platform Job Interface\n",
    "To access a job you need the model id from e.g. the model path https://platform.brevetti.ai/models/<model_id> and the api key, also accessible from the platform, which together grant you access to the data storage ressources.\n",
    "\n",
    "If you, instead, used the web api to get access to, and start a model, they id and key can be found in the response\n",
    "\n",
    "* model_id = model_def[\"id\"]\n",
    "\n",
    "* api_key = model_def[\"apiKey\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_8OEyxxJdTb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job model id (can be read from url https://platform.brevetti.ai/models/{model_id})ae03ff72-b7a2-444d-8fe9-623f61dc4c71\n",
      "Training job Api Key:········\n"
     ]
    }
   ],
   "source": [
    "# Job info: NB: replace with ID and api key from your job\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "model_id = os.getenv(\"job_id\") or input(\"Training job model id (can be read from url https://platform.brevetti.ai/models/{model_id})\")\n",
    "api_key = os.getenv(\"api_key\") or getpass.getpass(\"Training job Api Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y9prN9dRB8xF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs <class 'NoneType'> not known\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:brevettiai.platform.job:Config args found at: 's3://data.criterion.ai/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/info.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs <class 'NoneType'> not known\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:brevettiai.platform.job:Uploading output.json to s3://data.criterion.ai/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/artifacts/output.json\n"
     ]
    }
   ],
   "source": [
    "from brevettiai.platform import Job\n",
    "from brevettiai.interfaces import vue_schema_utils\n",
    " \n",
    "job = Job.init(job_id=model_id, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "The *brevettiai* library contains an interface to easily serialize and deserialize objects in json format. This has several advantages in designing image computer vision pipelines\n",
    "* It is easy to alter parameters when running new training jobs / experiments\n",
    "* The training process parameters can stored for each experiment to keep track of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original object config: \n",
      " {'param_1': 1, 'param_2': 'Test', 'param_3': {'test_dict_serialization': 'nested'}, 'custom': {'custom_param': 0}}\n",
      "Deserialized object config: \n",
      " {'param_1': 1, 'param_2': 'Test', 'param_3': {'test_dict_serialization': 'nested'}, 'custom': {'custom_param': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Job info: NB: replace with ID and api key from your job\n",
    "from brevettiai.interfaces.vue_schema_utils import VueSettingsModule\n",
    "\n",
    "\n",
    "class MyCustomObject(VueSettingsModule):\n",
    "    def __init__(self, custom_param: int = 0):\n",
    "        self.custom_param = custom_param\n",
    "\n",
    "\n",
    "class SerializeableObject(VueSettingsModule):\n",
    "    def __init__(self, param_1: float = -1.0, param_2: str = None, param_3: dict = None, custom: MyCustomObject = None):\n",
    "        self.param_1 = param_1\n",
    "        self.param_2 = param_2 or \"Param2 not provided\"\n",
    "        self.param_3 = param_3 or {\"nested_param\"}\n",
    "        self.custom = custom or MyCustomObject()\n",
    "\n",
    "my_object = SerializeableObject(param_1=1, param_2=\"Test\", param_3={\"test_dict_serialization\": \"nested\"})\n",
    "# Serialize objects with get_config\n",
    "config = my_object.get_config()\n",
    "\n",
    "print(\"Original object config: \\n\", config)\n",
    "\n",
    "# Deserialize objects with from_config\n",
    "my_object_copy = SerializeableObject.from_config(config)\n",
    "\n",
    "print(\"Deserialized object config: \\n\", my_object_copy.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job.Settings\n",
    "parsing settings to a training job using command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:brevettiai.platform.job:Config args found at: 's3://data.criterion.ai/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/info.json'\n",
      "WARNING:brevettiai.utils.module:Invalid config keys: some_setting_i_need\n",
      "INFO:brevettiai.platform.job:Uploading output.json to s3://data.criterion.ai/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/artifacts/output.json\n"
     ]
    }
   ],
   "source": [
    "from brevettiai.platform import Job\n",
    "import sys\n",
    "\n",
    "# Parsing parameters using command line args will set the settings in the nested object\n",
    "# job.settings\n",
    "\n",
    "# For classes hinted to be an object type as 'dict', 'list' etc the parameter text will be json parsed\n",
    "\n",
    "sys.argv += [\"--param_3\", '{\"test_dict_serialization\": \"nested2\"}',\n",
    "             \"--custom.custom_param\", \"5\"]\n",
    "\n",
    "class MiniJobWithCustomSettings(Job):\n",
    "    Settings = SerializeableObject\n",
    "    settings: Settings\n",
    "\n",
    "job = MiniJobWithCustomSettings.init(job_id=model_id, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'param_1': -1.0, 'param_2': 'Param2 not provided', 'param_3': {'test_dict_serialization': 'nested2'}, 'custom': {'custom_param': 5}}\n",
      "<__main__.MyCustomObject object at 0x000001DF853156C8> {'custom_param': 5}\n"
     ]
    }
   ],
   "source": [
    "print(job.settings.get_config()) # NB: param_3 and custom has been initialized by the command line parameters assigned above\n",
    "print(job.settings.custom, job.settings.custom.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will upload a serialized version of the training pipeline whenever a job is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:brevettiai.platform.job:Uploading output.json to s3://data.criterion.ai/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/artifacts/output.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'artifacts/output.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.upload_job_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIVg902QC9jW"
   },
   "source": [
    "## Storage\n",
    "\n",
    "In the job context you have two storage modes, temporary and persisted storage. Temporary storage is local on the machine, while the persisted storage is in the cloud in the form of artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lLnU5pgYC9jW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MICHAE~1\\AppData\\Local\\Temp\\config-id-ae03ff72-b7a2-444d-8fe9-623f61dc4c71-q2_ertbm\\something_i_want_to_save_temporarily.txt\n",
      "Valuable information\n"
     ]
    }
   ],
   "source": [
    "temp_path = job.temp_path(\"something_i_want_to_save_temporarily.txt\")\n",
    "print(temp_path)\n",
    "\n",
    "job.io.write_file(temp_path, \"Valuable information\")\n",
    "print(str(job.io.read_file(temp_path), \"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "INQ9DqiUC9jZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available at on the website: https://platform.brevetti.ai/models/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/artifacts\n",
      "Valuable information\n"
     ]
    }
   ],
   "source": [
    "artifact_path = job.artifact_path(\"something_i_want_to_save.txt\")\n",
    "print(f\"Available at on the website: {job.host_name}/models/{job.id}/artifacts\")\n",
    "\n",
    "# And in from the job\n",
    "job.io.write_file(artifact_path, \"Valuable information\")\n",
    "print(str(job.io.read_file(artifact_path), \"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMDACaI7C9jb"
   },
   "source": [
    "# API: Accessing datasets and downloading samples\n",
    "Samples in a dataset can be accessed via the dataset objects in a platform job object. Access rights are managed seamlessly.\n",
    "\n",
    "Sample integrity and purpose management can be done easily through the sample integrity module, which splits the samples for test and training, taking duplicates, stratification, etc. into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JY60bZkYC9jc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:brevettiai.platform.dataset:Getting image samples from dataset 'NeurIPS vials TRAIN' [https://platform.brevetti.ai/data/cb14b6e3-b4b9-45bb-955f-47aa6489a192]\n",
      "INFO:brevettiai.platform.dataset:Contents: {('good',): 20, ('missing_cap',): 20, ('failed_cap',): 19, ('unknown',): 1}\n"
     ]
    }
   ],
   "source": [
    "samples = job.datasets[0].get_image_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7MaZQcXSC9je"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:brevettiai.data.sample_integrity:Looking for previous train / development split\n",
      "INFO:brevettiai.data.sample_integrity:Using train / development split from run cached in artifacts\n"
     ]
    }
   ],
   "source": [
    "from brevettiai.data.sample_integrity import SampleSplit\n",
    "samples = SampleSplit().update_unassigned(samples, id_path=job.artifact_path(\"sample_identification.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UFnEZMSgC9ji"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>folder</th>\n",
       "      <th>path</th>\n",
       "      <th>etag</th>\n",
       "      <th>bucket</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>reference</th>\n",
       "      <th>url</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(failed_cap,)</td>\n",
       "      <td>failed_cap</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>18082de95a667ad2b5c11c23deaf21c0</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>NeurIPS vials TRAIN</td>\n",
       "      <td>cb14b6e3-b4b9-45bb-955f-47aa6489a192</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://platform.brevetti.ai/download?path=cb1...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(failed_cap,)</td>\n",
       "      <td>failed_cap</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>419fc5612ae56336d02e0f375f742dbe</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>NeurIPS vials TRAIN</td>\n",
       "      <td>cb14b6e3-b4b9-45bb-955f-47aa6489a192</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://platform.brevetti.ai/download?path=cb1...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(failed_cap,)</td>\n",
       "      <td>failed_cap</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>775b42ac52b75ed04b55f28ed66405b6</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>NeurIPS vials TRAIN</td>\n",
       "      <td>cb14b6e3-b4b9-45bb-955f-47aa6489a192</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://platform.brevetti.ai/download?path=cb1...</td>\n",
       "      <td>devel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(failed_cap,)</td>\n",
       "      <td>failed_cap</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>f3c08ff44efd25d37ff1247f6c18e552</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>NeurIPS vials TRAIN</td>\n",
       "      <td>cb14b6e3-b4b9-45bb-955f-47aa6489a192</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://platform.brevetti.ai/download?path=cb1...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(failed_cap,)</td>\n",
       "      <td>failed_cap</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>5dfab5b9037abb99b0a17b073d7dcf2e</td>\n",
       "      <td>s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...</td>\n",
       "      <td>NeurIPS vials TRAIN</td>\n",
       "      <td>cb14b6e3-b4b9-45bb-955f-47aa6489a192</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://platform.brevetti.ai/download?path=cb1...</td>\n",
       "      <td>devel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category      folder  \\\n",
       "0  (failed_cap,)  failed_cap   \n",
       "1  (failed_cap,)  failed_cap   \n",
       "2  (failed_cap,)  failed_cap   \n",
       "3  (failed_cap,)  failed_cap   \n",
       "4  (failed_cap,)  failed_cap   \n",
       "\n",
       "                                                path  \\\n",
       "0  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...   \n",
       "1  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...   \n",
       "2  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...   \n",
       "3  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...   \n",
       "4  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...   \n",
       "\n",
       "                               etag  \\\n",
       "0  18082de95a667ad2b5c11c23deaf21c0   \n",
       "1  419fc5612ae56336d02e0f375f742dbe   \n",
       "2  775b42ac52b75ed04b55f28ed66405b6   \n",
       "3  f3c08ff44efd25d37ff1247f6c18e552   \n",
       "4  5dfab5b9037abb99b0a17b073d7dcf2e   \n",
       "\n",
       "                                              bucket              dataset  \\\n",
       "0  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...  NeurIPS vials TRAIN   \n",
       "1  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...  NeurIPS vials TRAIN   \n",
       "2  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...  NeurIPS vials TRAIN   \n",
       "3  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...  NeurIPS vials TRAIN   \n",
       "4  s3://data.criterion.ai/cb14b6e3-b4b9-45bb-955f...  NeurIPS vials TRAIN   \n",
       "\n",
       "                             dataset_id reference  \\\n",
       "0  cb14b6e3-b4b9-45bb-955f-47aa6489a192       N/A   \n",
       "1  cb14b6e3-b4b9-45bb-955f-47aa6489a192       N/A   \n",
       "2  cb14b6e3-b4b9-45bb-955f-47aa6489a192       N/A   \n",
       "3  cb14b6e3-b4b9-45bb-955f-47aa6489a192       N/A   \n",
       "4  cb14b6e3-b4b9-45bb-955f-47aa6489a192       N/A   \n",
       "\n",
       "                                                 url purpose  \n",
       "0  https://platform.brevetti.ai/download?path=cb1...   train  \n",
       "1  https://platform.brevetti.ai/download?path=cb1...   train  \n",
       "2  https://platform.brevetti.ai/download?path=cb1...   devel  \n",
       "3  https://platform.brevetti.ai/download?path=cb1...   train  \n",
       "4  https://platform.brevetti.ai/download?path=cb1...   devel  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eiInPZ0C9jl"
   },
   "source": [
    "## Loading datasets\n",
    "File operations can be performed via the io_tools object. This object manages access of local and remote resources across windows and linux platforms. along with local cachin of files etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PynKvhvlC9jl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'BM6L\\x02\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# io_tools is accessible from the job object or directly via import 'from brevettiai.io import io_tools'\n",
    "# Note that access rights are configured on the IoTools object, and as such different instances of the object\n",
    "# does not neccesarily have access to the same files. \n",
    "io_tools = job.io\n",
    "buf = io_tools.read_file(samples.path[0])\n",
    "buf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gFF86hzEC9jo"
   },
   "outputs": [],
   "source": [
    "# Set caching of remote objects globally for all operations on the IoTools object\n",
    "io_tools.set_cache_root(job.temp_path(\"cache\", dir=True))\n",
    "# Or as a key in the read_file method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rt7N_zcNC9jr"
   },
   "source": [
    "## Loading image data with tensorflow datasets\n",
    "Samples may be easily loaded into tensorflow datasets with the **DataGenerator** class. **DataGenerator** contains a lot of functionality out of the box. Among others to sample, shuffle and seed your data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "c4gtdCJQC9jr"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.data_generator import StratifiedSampler, DataGenerator, OneHotEncoder\n",
    "from brevettiai.data.image import ImagePipeline, ImageAugmenter, SegmentationLoader\n",
    "\n",
    "ds = StratifiedSampler().get(samples, shuffle=True, batch_size=8, output_structure=(\"path\", \"folder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkpoGudDC9ju"
   },
   "source": [
    "The DataGenerator has four methods to iterate over data.\n",
    "\n",
    "First returning tensorflow datasets:\n",
    "\n",
    "* `get_samples()` returning the dataset sampled, but with no mapping\n",
    "* `get_dataset()` returning the dataset sampled and mapped\n",
    "\n",
    "Likewise `get_samples_numpy()` and `get_dataset_numpy()` returning numpy iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZEXdDmMC9jv"
   },
   "outputs": [],
   "source": [
    "# Return Data Geneator as tensorflow dataset objects to loop over samples or \"img\" and \"category\"\n",
    "ds.get_samples(), ds.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGcoPP4kC9jy"
   },
   "outputs": [],
   "source": [
    "# Get iterator of numpy objects\n",
    "ds.get_samples_numpy(), ds.get_dataset_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFvyXumBC9j0"
   },
   "source": [
    "As tensorflow datasets, you can map the dataset with functions.\n",
    "Among premade functions are ImagePipeline, ImageAugmenter, OneHotEncoder and AnnotationParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfvHv-bgC9j1"
   },
   "outputs": [],
   "source": [
    "ds = DataGenerator(samples, shuffle=True, batch_size=8, output_structure=(\"img\", \"onehot\"))\n",
    "ds = ds.map(ImagePipeline(target_size=(64,64), antialias=True, rescale=\"imagenet\")) \\\n",
    "    .map(OneHotEncoder(samples.folder.unique(), output_key=\"onehot\"))\n",
    "\n",
    "# Use the structure change the default structure of the ouput\n",
    "ds.get_dataset(structure=(\"path\", \"img\", \"onehot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcAoPaDfC9j3"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.image.utils import tile2d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use structure=None to access all the dataset elements\n",
    "x = next(ds.get_dataset_numpy(structure=None))\n",
    "plt.imshow(tile2d(x[\"img\"], (2,4))[...,0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M6XoHG8C9j5"
   },
   "outputs": [],
   "source": [
    "# Use structure=\"img\" to get just the image\n",
    "x = next(ds.get_dataset_numpy(structure=\"img\"))\n",
    "plt.imshow(tile2d(x, (2,4))[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXWPeiCgC9j8"
   },
   "source": [
    "Using `build_image_data_generator` makes a simple dataset, combining loading, augmentation and onehot encoding og categories, and returning an (image, onehot) tuple which may be used directly as input to keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iixs-fnlC9j8"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.data_generator import build_image_data_generator\n",
    "ds = build_image_data_generator(samples, batch_size=8, image=dict(target_size=(224, 224), antialias=True, rescale=\"imagenet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoN4w-PeC9j_"
   },
   "source": [
    "The standard modules of Dataset are deterministic and randomness may be seeded. Thus multiple runs of the same dataset object will result in the same output sequence. By application of the `seed` parameter, this can be true across multiple similar TfDataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ngDb9jFC9kA"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.data_generator import build_image_data_generator\n",
    "ds = build_image_data_generator(samples, batch_size=8, image=dict(target_size=(224, 224), antialias=True, rescale=\"imagenet\"))\n",
    "x = next(ds.get_dataset_numpy())\n",
    "plt.figure()\n",
    "plt.title(\"Run 1\")\n",
    "plt.imshow(tile2d(x[0], (2,4))[...,0])\n",
    "plt.figure()\n",
    "plt.title(\"Run 2 of the same dataset results in the same sampling and augmentation performed on the dataset\")\n",
    "x = next(ds.get_dataset_numpy())\n",
    "plt.imshow(tile2d(x[0], (2,4))[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVMUv1DdC9kC"
   },
   "source": [
    "# API: Interfaces / integrations\n",
    "##Job output to platform website\n",
    "A number of different outputs are available on the platform, here is a subset.\n",
    "\n",
    "## Metrics\n",
    "Metrics which may be compared across models can be added via the config object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPgK9gO1C9kD"
   },
   "outputs": [],
   "source": [
    "print(f\"Uploading metrics and outputs to {job.host_name}/models/{model_id}/artifacts\")\n",
    "job.add_output_metric(\"My custom metric\", 277)\n",
    "job.upload_job_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x__gkiUBCkkN"
   },
   "source": [
    "## Progress monitoring (Models only)\n",
    "Add progress metrics to monitor your models while it is running, by adding the RemoteMonitor callback to your keras training loop or call it yourself in your training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23ZngZ5bCoAL"
   },
   "outputs": [],
   "source": [
    "from brevettiai.interfaces.remote_monitor import RemoteMonitor\n",
    "remote_monitor_callback = RemoteMonitor(root=job.host_name, path=job.api_endpoints[\"remote\"])\n",
    "# Simulate training epochs and produce callbacks\n",
    "remote_monitor_callback.on_epoch_end(11, {\"loss\": 0.9, \"accuracy\": 0.5})\n",
    "remote_monitor_callback.on_epoch_end(12, {\"loss\": 0.7, \"accuracy\": 0.8})\n",
    "\n",
    "print(f\"Training progress visible on {job.host_name}/models/{model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2_wHC-HC9kH"
   },
   "source": [
    "## Pivot tables\n",
    "\n",
    "create pivot tables on the web platform to get an overview over your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5MJIUH5C9kH"
   },
   "outputs": [],
   "source": [
    "from brevettiai.interfaces.pivot import export_pivot_table, get_default_fields, pivot_fields\n",
    "export_pivot_table(job.artifact_path(\"pivot\", dir=True), samples,\n",
    "                   datasets=job.datasets,\n",
    "                   fields=None,\n",
    "                   tags=job.get_root_tags(),\n",
    "                   rows=[\"dataset_id\"],\n",
    "                   cols=[\"category\"],\n",
    "                   agg={\"url\": \"first\"})\n",
    "print(f\"Pivot table visible on {job.host_name}/models/{model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBT0_SfPC9kK"
   },
   "source": [
    "## Facets\n",
    "Create facet dives to explore your data in depth by creating a dataset outputting thumbnails of size (64x64) per sample. \n",
    "![Facet example](https://gblobscdn.gitbook.com/assets%2F-LY12YhLSCDWlqNaQqWT%2F-MIdFH6dqJxgrYtQH83E%2F-MIdJ3qn1kPxLh6K0YI0%2Fimage.png?alt=media&token=d59993dc-9dd0-4f97-a548-4d6ceddf257d)\n",
    "\n",
    "Put the files in the facets folder in your artifacts. To use the built-in tools you need to supply a DataGenerator which outputs a 64x64 thumbnail image, and category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7I0XpmMC9kK"
   },
   "outputs": [],
   "source": [
    "from brevettiai.interfaces.facets_atlas import build_facets\n",
    "from brevettiai.data.data_generator import StratifiedSampler, DataGenerator\n",
    "fds = DataGenerator(samples, shuffle=True, output_structure=(\"img\", \"category\")) \\\n",
    "    .map(ImagePipeline(target_size=(64,64), antialias=True))\n",
    "\n",
    "build_facets(fds, job.artifact_path(\"facets\", dir=True), count=32)\n",
    "\n",
    "print(f\"Facets visible on {job.host_name}/models/{model_id}\")\n",
    "\n",
    "build_facets(fds, job.artifact_path(\"facets\", dir=True), count=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKlFaciBkO00"
   },
   "source": [
    "## Vega-lite charts\n",
    "Vega-Lite charts\n",
    "Add Vega-Lite charts to your model page by calling upload_chart on the configuration object. Some different standard charts are available under brevettiai.interfaces.vegalite_charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QPNxXw1kWy_"
   },
   "outputs": [],
   "source": [
    "from brevettiai.interfaces import vegalite_charts\n",
    "\n",
    "vegalite_json = vegalite_charts.dataset_summary(samples)\n",
    "job.upload_chart(\"demo\", vegalite_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajDPritL9Fti"
   },
   "source": [
    "# API: Complete job\n",
    "Update the following on the platform\n",
    "* The path to the model file (optional)\n",
    "* That the training or testing process is finished, so the UI can be updated\n",
    "* This revokes access to write to the job artifact path, and access to the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8mNpKoMmc4K"
   },
   "source": [
    "## Model export\n",
    "\n",
    "Export your model to an archive. ex a tar.gz zipped tensorflow saved\\_model. Place this model in the artifact path, and include the path in the job completion call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLtLcTkP9CQs"
   },
   "outputs": [],
   "source": [
    "# job.complete_job(exported_model_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "brevettiai_job_api_platform_interfaces_documentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
