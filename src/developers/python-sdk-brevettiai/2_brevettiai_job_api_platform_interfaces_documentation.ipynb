{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqbkhGASC9i6"
   },
   "source": [
    "---\n",
    "description: This section documents through examples the simple usage the job api's to access a model training job's artifacts, datasets and lots of other stuff  in a development context\n",
    "---\n",
    "# Introduction to Brevetti AI Job API\n",
    "The brevettiai Job API is your execution context when running a job on the platform. A job being defined as a model training process, or the process of creating a test report. The brevettiai package is a lightweight api for interfacing with the cloud ressources.\n",
    "\n",
    "It provides a python interface to the website, and keeps track of the resources you have available there, and parsing of input in the form of settings to your code.\n",
    "\n",
    "![Job API](https://gblobscdn.gitbook.com/assets%2F-LY12YhLSCDWlqNaQqWT%2Fsync%2F5bd21284c912c0d6b26828d4d36358c7445f44fd.png)\n",
    "\n",
    "From the platform, a job \\(model or test report\\) is an input configuration with a storage space attached. The storage space freely available to use by the job, but following a few conventions, allows the platform to parse specific content for display on the model page.\n",
    "\n",
    "This section explores its usage from the perspective of a developer training models on his/her own computer.\n",
    "Except for the initialization of the environment, all of the code is transferrable to a docker containerized deployment of model training on the platform.\n",
    "\n",
    "Use help(CriterionConfig) to get an overview over available methods.\n",
    "\n",
    "##Job object\n",
    "A Job in the python code is collected into a single object containing its state and settings at runtime. you can use the Job object directly, or subclass it to add your own functionality.\n",
    "Settings may be added to a job by subclassing the Job object, and changing the settings parameter type to a settings object to a new JobSettings object.\n",
    "\n",
    "```python\n",
    "from brevettiai import Job, JobSettings\n",
    "class MyJobSettings(JobSettings):\n",
    "    my_custom_int_setting: int\n",
    "    \n",
    "class MyJob(Job):\n",
    "    settings: MyJobSettings\n",
    "    \n",
    "    def run(self):\n",
    "        print(f\"My setting is {self.my_custom_setting}\")\n",
    "        return None\n",
    "\n",
    "job = MyJob.init(job_id='UUID', api_key='key')\n",
    "job.start()\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Settings may themselves subclass JobSettings, pydantic BaseModel, pydantic dataclasses or python dataclasses. \n",
    "resulting in a tree of settings.\n",
    "Like the job_id and apikey the settings may be set from argv using a dot notation (`--setting_name.sub_setting 42`).\n",
    "for the job above, this may be set as `--my_custom_int_setting 37`. To add information about the field,\n",
    "use the pydantic Field class as default value. \n",
    "\n",
    "## Job lifecycle\n",
    "\n",
    "### Initialize\n",
    "To begin executing a job you first need do get an execution context. retrieving settings datasets, access rights, etc.\n",
    "to do this you call the init function on a brevetti Job object.\n",
    "```python\n",
    "from brevettiai import Job\n",
    "job = Job.init()\n",
    "```\n",
    "The init function can use either arguments on the function or command line\n",
    "arguments `--job_id` and `--api_key` to find the job on the brevetti ai platform\n",
    "\n",
    "### Start\n",
    "The Job is started by running the start() member function.\n",
    "By default this will upload a job output json file to the job, call the run function, and then complete the job.\n",
    "Overwrite the `Job.run()` function to perform the job you would like, returning a path to a locally stored model output that you want associated with the completed job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzEXlRHhEavu"
   },
   "source": [
    "# Brevetti AI package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7MCqSgiEY83"
   },
   "outputs": [],
   "source": [
    "pip install brevettiai[tfa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6uIDiTBC9i8"
   },
   "outputs": [],
   "source": [
    "# Imports and setup to avoid extensive verboisty\n",
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig()\n",
    "log.root.setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: JobSettings\n",
    "The *Brevetti AI platform* has an interface to set job settings, which may in turn be parsed using the *brevettiai* JobSettings class. Generally, it is desirable to have an interface to easily serialize and deserialize objects in json format. This has several advantages in designing image computer vision pipelines\n",
    "* It is easy to alter parameters when running new training jobs / experiments\n",
    "* The training process parameters can be stored for each experiment to keep track of experiments\n",
    "\n",
    "Parameters should be specified with type hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "from brevettiai import Job, JobSettings\n",
    "class MyJobSettings(JobSettings):\n",
    "    my_custom_int_setting: int = Field(default=25,\n",
    "                        description=\"My own custom integer setting\", advanced=False)\n",
    "\n",
    "class MyJob(Job):\n",
    "    settings: MyJobSettings\n",
    "    \n",
    "    def run(self): # This function should be overloaded and is run when job is started\n",
    "\n",
    "        print(f\"Run my custom code using custom parameter \\\"my_custom_int_setting\\\": {self.settings.my_custom_int_setting}\")\n",
    "        \n",
    "        return None # Return path to model artifacts to be uploaded after job is completed\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3faNHKZdTb0"
   },
   "source": [
    "# API: BrevettiAI Platform Job Interface\n",
    "To access a job you need the model id from e.g. the model path https://platform.brevetti.ai/models/<model_id> and the api key, also accessible from the platform, which together grant you access to the data storage ressources.\n",
    "\n",
    "If you, instead, used the web api to get access to, and start a model, they id and key can be found in the response\n",
    "\n",
    "* model_id = model_def[\"id\"]\n",
    "\n",
    "* api_key = model_def[\"apiKey\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8OEyxxJdTb1"
   },
   "outputs": [],
   "source": [
    "# Job info: NB: replace with ID and api key from your job\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "model_id = os.getenv(\"job_id\") or input(\"Training job model id (can be read from url https://platform.brevetti.ai/models/{model_id})\")\n",
    "api_key = os.getenv(\"api_key\") or getpass.getpass(\"Training job Api Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9prN9dRB8xF"
   },
   "outputs": [],
   "source": [
    "job = MyJob.init(job_id=model_id, api_key=api_key)\n",
    "job.start(complete=False)\n",
    "job.settings.my_custom_int_setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overriding Job.Settings from command line\n",
    "parsing settings to a training job using command line arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevettiai.platform import Job\n",
    "import sys\n",
    "\n",
    "# Parsing parameters using command line args will set the settings in the nested object\n",
    "# job.settings\n",
    "\n",
    "# For classes hinted to be an object type as 'dict', 'list' etc the parameter text will be json parsed\n",
    "\n",
    "sys.argv += [\"--my_custom_int_setting\", '10']\n",
    "\n",
    "job = MyJob.init(job_id=model_id, api_key=api_key)\n",
    "job.start(complete=False)\n",
    "job.settings.my_custom_int_setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will upload a serialized version of the training pipeline whenever a job is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.upload_job_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIVg902QC9jW"
   },
   "source": [
    "## Storage\n",
    "\n",
    "In the job context you have two storage modes, temporary and persisted storage. Temporary storage is local on the machine, while the persisted storage is in the cloud in the form of artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLnU5pgYC9jW"
   },
   "outputs": [],
   "source": [
    "temp_path = job.temp_path(\"something_i_want_to_save_temporarily.txt\")\n",
    "print(temp_path)\n",
    "\n",
    "job.io.write_file(temp_path, \"Valuable information\")\n",
    "print(str(job.io.read_file(temp_path), \"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INQ9DqiUC9jZ"
   },
   "outputs": [],
   "source": [
    "artifact_path = job.artifact_path(\"something_i_want_to_save.txt\")\n",
    "print(f\"Available at on the website: {job.host_name}/models/{job.id}/artifacts\")\n",
    "\n",
    "# And in from the job\n",
    "job.io.write_file(artifact_path, \"Valuable information\")\n",
    "print(str(job.io.read_file(artifact_path), \"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMDACaI7C9jb"
   },
   "source": [
    "# API: Accessing datasets and downloading samples\n",
    "Samples in a dataset can be accessed via the dataset objects in a platform job object. Access rights are managed seamlessly.\n",
    "\n",
    "Sample integrity and purpose management can be done easily through the sample integrity module, which splits the samples for test and training, taking duplicates, stratification, etc. into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JY60bZkYC9jc"
   },
   "outputs": [],
   "source": [
    "samples = job.datasets[0].get_image_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MaZQcXSC9je"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.sample_integrity import SampleSplit\n",
    "samples = SampleSplit().update_unassigned(samples, id_path=job.artifact_path(\"sample_identification.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFnEZMSgC9ji"
   },
   "outputs": [],
   "source": [
    "samples.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eiInPZ0C9jl"
   },
   "source": [
    "## Loading datasets\n",
    "File operations can be performed via the io_tools object. This object manages access of local and remote resources across windows and linux platforms. along with local cachin of files etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PynKvhvlC9jl"
   },
   "outputs": [],
   "source": [
    "# io_tools is accessible from the job object or directly via import 'from brevettiai.io import io_tools'\n",
    "# Note that access rights are configured on the IoTools object, and as such different instances of the object\n",
    "# does not neccesarily have access to the same files. \n",
    "io_tools = job.io\n",
    "buf = io_tools.read_file(samples.path[0])\n",
    "buf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFF86hzEC9jo"
   },
   "outputs": [],
   "source": [
    "# Set caching of remote objects globally for all operations on the IoTools object\n",
    "io_tools.set_cache_root(job.temp_path(\"cache\", dir=True))\n",
    "# Or as a key in the read_file method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rt7N_zcNC9jr"
   },
   "source": [
    "## Loading image data with tensorflow datasets\n",
    "Samples may be easily loaded into tensorflow datasets with the **DataGenerator** class. **DataGenerator** contains a lot of functionality out of the box. Among others to sample, shuffle and seed your data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4gtdCJQC9jr"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.data_generator import StratifiedSampler, DataGenerator, OneHotEncoder\n",
    "from brevettiai.data.image import ImagePipeline, ImageAugmenter, SegmentationLoader\n",
    "\n",
    "ds = StratifiedSampler().get(samples.drop(columns=[\"reference\"]), shuffle=True, batch_size=8, output_structure=(\"path\", \"folder\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkpoGudDC9ju"
   },
   "source": [
    "The DataGenerator has four methods to iterate over data.\n",
    "\n",
    "First returning tensorflow datasets:\n",
    "\n",
    "* `get_samples()` returning the dataset sampled, but with no mapping\n",
    "* `get_dataset()` returning the dataset sampled and mapped\n",
    "\n",
    "Likewise `get_samples_numpy()` and `get_dataset_numpy()` returning numpy iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZEXdDmMC9jv"
   },
   "outputs": [],
   "source": [
    "# Return Data Geneator as tensorflow dataset objects to loop over samples or \"img\" and \"category\"\n",
    "ds.get_samples(), ds.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGcoPP4kC9jy"
   },
   "outputs": [],
   "source": [
    "# Get iterator of numpy objects\n",
    "ds.get_samples_numpy(), ds.get_dataset_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFvyXumBC9j0"
   },
   "source": [
    "As tensorflow datasets, you can map the dataset with functions.\n",
    "Among premade functions are ImagePipeline, ImageAugmenter, OneHotEncoder and AnnotationParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfvHv-bgC9j1"
   },
   "outputs": [],
   "source": [
    "ds = DataGenerator(samples, shuffle=True, batch_size=8, output_structure=(\"img\", \"onehot\"))\n",
    "ds = ds.map(ImagePipeline(target_size=(64,64), antialias=True, rescale=\"imagenet\")) \\\n",
    "    .map(OneHotEncoder(samples.folder.unique(), output_key=\"onehot\"))\n",
    "\n",
    "# Use the structure change the default structure of the ouput\n",
    "ds.get_dataset(structure=(\"path\", \"img\", \"onehot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcAoPaDfC9j3"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.image.utils import tile2d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use structure=None to access all the dataset elements\n",
    "x = next(ds.get_dataset_numpy(structure=None))\n",
    "plt.imshow(tile2d(x[\"img\"], (2, 4))[..., 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2M6XoHG8C9j5"
   },
   "outputs": [],
   "source": [
    "# Use structure=\"img\" to get just the image\n",
    "x = next(ds.get_dataset_numpy(structure=\"img\"))\n",
    "plt.imshow(tile2d(x, (2,4))[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXWPeiCgC9j8"
   },
   "source": [
    "Using `build_image_data_generator` makes a simple dataset, combining loading, augmentation and onehot encoding og categories, and returning an (image, onehot) tuple which may be used directly as input to keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iixs-fnlC9j8"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.data_generator import build_image_data_generator\n",
    "ds = build_image_data_generator(samples, batch_size=8, image=dict(target_size=(224, 224), antialias=True, rescale=\"imagenet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoN4w-PeC9j_"
   },
   "source": [
    "The standard modules of Dataset are deterministic and randomness may be seeded. Thus multiple runs of the same dataset object will result in the same output sequence. By application of the `seed` parameter, this can be true across multiple similar TfDataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ngDb9jFC9kA"
   },
   "outputs": [],
   "source": [
    "from brevettiai.data.data_generator import build_image_data_generator\n",
    "ds = build_image_data_generator(samples, batch_size=8, image=dict(target_size=(224, 224), antialias=True, rescale=\"imagenet\"))\n",
    "x = next(ds.get_dataset_numpy())\n",
    "plt.figure()\n",
    "plt.title(\"Run 1\")\n",
    "plt.imshow(tile2d(x[0], (2,4))[...,0])\n",
    "plt.figure()\n",
    "plt.title(\"Run 2 of the same dataset results in the same sampling and augmentation performed on the dataset\")\n",
    "x = next(ds.get_dataset_numpy())\n",
    "plt.imshow(tile2d(x[0], (2,4))[...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVMUv1DdC9kC"
   },
   "source": [
    "# API: Interfaces / integrations\n",
    "##Job output to platform website\n",
    "A number of different outputs are available on the platform, here is a subset.\n",
    "\n",
    "## Metrics\n",
    "Metrics which may be compared across models can be added via the config object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPgK9gO1C9kD"
   },
   "outputs": [],
   "source": [
    "print(f\"Uploading metrics and outputs to {job.host_name}/models/{model_id}/artifacts\")\n",
    "job.add_output_metric(\"My custom metric\", 277)\n",
    "job.upload_job_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x__gkiUBCkkN"
   },
   "source": [
    "## Progress monitoring (Models only)\n",
    "Add progress metrics to monitor your models while it is running, by adding the RemoteMonitor callback to your keras training loop or call it yourself in your training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23ZngZ5bCoAL"
   },
   "outputs": [],
   "source": [
    "remote_monitor_callback = job.get_remote_monitor()\n",
    "# Simulate training epochs and produce callbacks\n",
    "remote_monitor_callback.on_epoch_end(11, {\"loss\": 0.9, \"accuracy\": 0.5})\n",
    "remote_monitor_callback.on_epoch_end(12, {\"loss\": 0.7, \"accuracy\": 0.8})\n",
    "\n",
    "print(f\"Training progress visible on {job.host_name}/models/{model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2_wHC-HC9kH"
   },
   "source": [
    "## Pivot tables\n",
    "\n",
    "create pivot tables on the web platform to get an overview over your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5MJIUH5C9kH"
   },
   "outputs": [],
   "source": [
    "from brevettiai.interfaces.pivot import export_pivot_table, get_default_fields, pivot_fields\n",
    "export_pivot_table(job.artifact_path(\"pivot\", dir=True), samples,\n",
    "                   datasets=job.datasets,\n",
    "                   fields=None,\n",
    "                   tags=job.backend.get_root_tags(job.id, job.api_key),\n",
    "                   rows=[\"dataset_id\"],\n",
    "                   cols=[\"category\"],\n",
    "                   agg={\"url\": \"first\"})\n",
    "print(f\"Pivot table visible on {job.host_name}/models/{model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBT0_SfPC9kK"
   },
   "source": [
    "## Facets\n",
    "Create facet dives to explore your data in depth by creating a dataset outputting thumbnails of size (64x64) per sample. \n",
    "![Facet example](https://gblobscdn.gitbook.com/assets%2F-LY12YhLSCDWlqNaQqWT%2F-MIdFH6dqJxgrYtQH83E%2F-MIdJ3qn1kPxLh6K0YI0%2Fimage.png?alt=media&token=d59993dc-9dd0-4f97-a548-4d6ceddf257d)\n",
    "\n",
    "Put the files in the facets folder in your artifacts. To use the built-in tools you need to supply a DataGenerator which outputs a 64x64 thumbnail image, and category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7I0XpmMC9kK"
   },
   "outputs": [],
   "source": [
    "from brevettiai.interfaces.facets_atlas import build_facets\n",
    "from brevettiai.data.data_generator import StratifiedSampler, DataGenerator\n",
    "fds = DataGenerator(samples, shuffle=True, output_structure=(\"img\", \"category\")) \\\n",
    "    .map(ImagePipeline(target_size=(64,64), antialias=True))\n",
    "\n",
    "build_facets(fds, job.artifact_path(\"facets\", dir=True), count=32)\n",
    "\n",
    "print(f\"Facets visible on {job.host_name}/models/{model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajDPritL9Fti"
   },
   "source": [
    "# API: Complete job\n",
    "Update the following on the platform\n",
    "* The path to the model file (optional)\n",
    "* That the training or testing process is finished, so the UI can be updated\n",
    "* This revokes access to write to the job artifact path, and access to the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8mNpKoMmc4K"
   },
   "source": [
    "## Model export\n",
    "\n",
    "Export your model to an archive. ex a tar.gz zipped tensorflow saved\\_model. Place this model in the artifact path, and include the path in the job completion call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLtLcTkP9CQs"
   },
   "outputs": [],
   "source": [
    "# job.complete_job(exported_model_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "brevettiai_job_api_platform_interfaces_documentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
