{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image Classifier model example\n",
    "This document introduces a simple image classifier model, to show how to build the necessary packages to host a model on the Brevetti AI platform. It includes the following necessary steps\n",
    "* Model training code that can also produce a user configuration ```settings_schema.json``` file\n",
    "  - should accept cmd args with **job_id** and **api_key** or find sagemaker hyperparameter file with the same\n",
    "  - should produce a model artifact\n",
    "  - these steps are handled by the ```brevettiai``` *Job* object\n",
    "* A simple Dockerfile to run the code - this is how the script is embedded on the platform\n",
    "\n",
    "## Basic keras Image classifier model\n",
    "As a minimal model example. The code below will serve as a simple model for image classification based on the MobileNet architecture. It accepts any number of classes and the image size may be specified.\n",
    "For training regularization, it includes a Dropout layer.\n",
    "The model and training code can be found on the documentation github repository [image_classifier.py](https://github.com/brevettiai/brevettiai-docs/blob/master/src/tutorials/image_classifier_101/image_classifier.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_image_classifier(classes: list, image_shape: tuple):\n",
    "    # Model backbone is the MobileNetV2\n",
    "    backbone = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=image_shape, include_top=False, weights=\"imagenet\"\n",
    "    )\n",
    "    # Features are pooled and the output layer consists of a single dense layer\n",
    "    model = tf.keras.Sequential([\n",
    "        backbone,\n",
    "        tf.keras.layers.GlobalMaxPooling2D(),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(len(classes), activation='softmax', name=\"---\".join(classes))\n",
    "    ])\n",
    "    # Model is compiled with ```categorical_crossentropy``` loss and reports accuracy metric\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using some default image size and classes a model generated with the above code, and we can verify that it seems to produce a valid keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "good---bad (Dense)           (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# test run of image classification build code\n",
    "test_model = build_image_classifier([\"good\", \"bad\"], (224, 224, 3))\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training *Job*\n",
    "To train and export the model, construct a training object that uses the following ```brevettiai``` components\n",
    " - the *Job* class implements the [Job API](https://docs.brevetti.ai/developers/python-sdk-brevettiai/2_brevettiai_job_api_platform_interfaces_documentation) which gives access to the Brevetti AI platform and the dataset ressources.\n",
    " - the *Settings* object ```Job.Settings``` specifies the configurable elements that we will use in the script. The parameters of these objects / variables may be specified by the platform user\n",
    " - ```package_saved_model``` module saves tensorflow saved_model file as tar gz for the deployment\n",
    " \n",
    " To install the ```brevettiai``` package simply run ```pip install -U git+https://bitbucket.org/criterionai/core```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brevettiai[tfa] in c:\\libs\\tf2\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (1.19.5)\n",
      "Requirement already satisfied: plotly>=4.14.3 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (4.14.3)\n",
      "Collecting tqdm>=4.62\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: requests>=2.23 in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from brevettiai[tfa]) (2.24.0)\n",
      "Requirement already satisfied: tf2onnx>=1.9.0 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (1.9.3)\n",
      "Requirement already satisfied: altair==4.1.0 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (4.1.0)\n",
      "Requirement already satisfied: cryptography<37.0.0,>=36.0.1 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (36.0.1)\n",
      "Requirement already satisfied: minio<7.1,>=7.0 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (7.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23.1 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (0.24.1)\n",
      "Requirement already satisfied: configparser>=5.0 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (5.0.0)\n",
      "Requirement already satisfied: backoff>=1.10 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (1.10.0)\n",
      "Requirement already satisfied: shapely>=1.7.0 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (1.7.1)\n",
      "Requirement already satisfied: mmh3>=3.0 in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from brevettiai[tfa]) (3.0.0)\n",
      "Requirement already satisfied: pydantic>=1.8.2 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (1.8.2)\n",
      "Requirement already satisfied: pandas<1.2,>=1.1 in c:\\libs\\tf2\\lib\\site-packages (from brevettiai[tfa]) (1.1.5)\n",
      "Collecting tensorflow_addons>=0.15.0\n",
      "  Using cached tensorflow_addons-0.15.0-cp37-cp37m-win_amd64.whl (753 kB)\n",
      "Requirement already satisfied: toolz in c:\\libs\\tf2\\lib\\site-packages (from altair==4.1.0->brevettiai[tfa]) (0.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\libs\\tf2\\lib\\site-packages (from altair==4.1.0->brevettiai[tfa]) (2.11.2)\n",
      "Requirement already satisfied: entrypoints in c:\\libs\\tf2\\lib\\site-packages (from altair==4.1.0->brevettiai[tfa]) (0.3)\n",
      "Requirement already satisfied: jsonschema in c:\\libs\\tf2\\lib\\site-packages (from altair==4.1.0->brevettiai[tfa]) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from cryptography<37.0.0,>=36.0.1->brevettiai[tfa]) (1.14.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from minio<7.1,>=7.0->brevettiai[tfa]) (2020.6.20)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from minio<7.1,>=7.0->brevettiai[tfa]) (1.25.10)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\libs\\tf2\\lib\\site-packages (from pandas<1.2,>=1.1->brevettiai[tfa]) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\libs\\tf2\\lib\\site-packages (from pandas<1.2,>=1.1->brevettiai[tfa]) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from plotly>=4.14.3->brevettiai[tfa]) (1.15.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\libs\\tf2\\lib\\site-packages (from plotly>=4.14.3->brevettiai[tfa]) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\libs\\tf2\\lib\\site-packages (from pydantic>=1.8.2->brevettiai[tfa]) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests>=2.23->brevettiai[tfa]) (3.0.4)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests>=2.23->brevettiai[tfa]) (2.10)\n",
      "\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\libs\\tf2\\lib\\site-packages (from scikit-learn>=0.23.1->brevettiai[tfa]) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\libs\\tf2\\lib\\site-packages (from scikit-learn>=0.23.1->brevettiai[tfa]) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\libs\\tf2\\lib\\site-packages (from scikit-learn>=0.23.1->brevettiai[tfa]) (0.16.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\libs\\tf2\\lib\\site-packages (from tensorflow_addons>=0.15.0->brevettiai[tfa]) (2.9.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12 in c:\\libs\\tf2\\lib\\site-packages (from tf2onnx>=1.9.0->brevettiai[tfa]) (1.12)\n",
      "Requirement already satisfied: onnx>=1.4.1 in c:\\libs\\tf2\\lib\\site-packages (from tf2onnx>=1.9.0->brevettiai[tfa]) (1.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm>=4.62->brevettiai[tfa]) (0.4.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from cffi>=1.12->cryptography<37.0.0,>=36.0.1->brevettiai[tfa]) (2.20)\n",
      "Requirement already satisfied: protobuf in c:\\libs\\tf2\\lib\\site-packages (from onnx>=1.4.1->tf2onnx>=1.9.0->brevettiai[tfa]) (3.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\libs\\tf2\\lib\\site-packages (from jinja2->altair==4.1.0->brevettiai[tfa]) (1.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\libs\\tf2\\lib\\site-packages (from jsonschema->altair==4.1.0->brevettiai[tfa]) (49.3.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\libs\\tf2\\lib\\site-packages (from jsonschema->altair==4.1.0->brevettiai[tfa]) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\libs\\tf2\\lib\\site-packages (from jsonschema->altair==4.1.0->brevettiai[tfa]) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jsonschema->altair==4.1.0->brevettiai[tfa]) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\michael sass hansen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->jsonschema->altair==4.1.0->brevettiai[tfa]) (3.1.0)\n",
      "Installing collected packages: tqdm, tensorflow-addons\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.56.0\n",
      "    Uninstalling tqdm-4.56.0:\n",
      "      Successfully uninstalled tqdm-4.56.0\n",
      "  Attempting uninstall: tensorflow-addons\n",
      "    Found existing installation: tensorflow-addons 0.12.0\n",
      "    Uninstalling tensorflow-addons-0.12.0:\n",
      "      Successfully uninstalled tensorflow-addons-0.12.0\n",
      "Successfully installed tensorflow-addons-0.15.0 tqdm-4.62.3\n"
     ]
    }
   ],
   "source": [
    "pip install brevettiai[tfa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform features useful for accessing the job parameters\n",
    "from brevettiai.platform import Job\n",
    "from brevettiai.data.sample_tools import BrevettiDatasetSamples\n",
    "from brevettiai.interfaces.remote_monitor import RemoteMonitor\n",
    "# packages model for upload\n",
    "from brevettiai.utils.model_version import package_saved_model\n",
    "\n",
    "# Data science tools for training an image classifier model\n",
    "from brevettiai.data.image import ImagePipeline\n",
    "from brevettiai.data.data_generator import DataGenerator, OneHotEncoder\n",
    "from brevettiai.interfaces.facets_atlas import build_facets\n",
    "\n",
    "\n",
    "class TrainingJob(Job):\n",
    "    class Settings(Job.Settings):\n",
    "        def __init__(self, image_pipeline: ImagePipeline, epochs: int = 2):\n",
    "            self.image_pipeline = image_pipeline # object to read image and resize to specified shape\n",
    "            self.epochs = epochs # number of training epochs\n",
    "    settings: Settings\n",
    "\n",
    "    def train(self):\n",
    "        # Get the samples and the classes from the job datasets \n",
    "        samples = BrevettiDatasetSamples().get_image_samples(self.datasets, annotations=False)\n",
    "        classes = samples.folder.unique()\n",
    "\n",
    "        # Setup up data generator to loop through the samples\n",
    "        data_generator = DataGenerator(samples, output_structure=(\"img\", \"onehot\"), shuffle=True, repeat=True,\n",
    "                                       max_epoch_samples=4, batch_size=4)\\\n",
    "            .map([self.settings.image_pipeline, OneHotEncoder(classes=classes, input_key=\"folder\")])\n",
    "\n",
    "        # Construct a keras image classifier model and train it using the data generator\n",
    "        model = build_image_classifier(classes, self.settings.image_pipeline.output_shape)\n",
    "        # Fit model for user specified number of epochs - remote monitor shows progress on platform\n",
    "        model.fit(data_generator.get_dataset(), epochs=self.settings.epochs, steps_per_epoch=len(data_generator),\n",
    "                  callbacks=[RemoteMonitor(root=self.host_name, path=self.api_endpoints[\"remote\"])])\n",
    "\n",
    "        # *** Building facets for visiualization of output ***\n",
    "        test_generator = DataGenerator(samples, output_structure=(\"img\"), shuffle=False, repeat=False)\\\n",
    "            .map(self.settings.image_pipeline)\n",
    "        samples[classes] = model.predict(test_generator.get_dataset(),\n",
    "                                         steps=len(test_generator))\n",
    "        fds = DataGenerator(samples, shuffle=True, output_structure=(\"img\"))\\\n",
    "            .map(ImagePipeline(target_size=(64,64), antialias=True))\n",
    "\n",
    "        build_facets(fds, job.artifact_path(\"facets\", dir=True), count=32)\n",
    "\n",
    "        print(f\"Facets visible on {self.host_name}/models/{self.id}\")\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def export(self, model):\n",
    "        # Save model and package it along with meta data\n",
    "        model.save(\"saved_model\", overwrite=True, include_optimizer=False)\n",
    "        return package_saved_model(\"saved_model\", model_meta={\"important_model_meta\": 42})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training job can be run in a python script; below is shown what is needed to run a training job, and also the TrainingJob class may be used to create the ```settings_schema.json``` file needed by the Brevetti AI platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:brevettiai.platform.job:Config args found at: 's3://data.criterion.ai/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/info.json'\n",
      "WARNING:brevettiai.utils.module:Invalid config keys: some_setting_i_need\n",
      "INFO:brevettiai.platform.job:Uploading output.json to s3://data.criterion.ai/ae03ff72-b7a2-444d-8fe9-623f61dc4c71/artifacts/output.json\n",
      "INFO:brevettiai.platform.dataset:Getting image samples from dataset 'NeurIPS vials TRAIN' [https://platform.brevetti.ai/data/cb14b6e3-b4b9-45bb-955f-47aa6489a192]\n",
      "INFO:brevettiai.platform.dataset:Contents: {('missing_cap',): 20, ('good',): 20, ('failed_cap',): 19}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: s3.eu-west-1.amazonaws.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 4.4857 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: s3.eu-west-1.amazonaws.com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.2331 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 501.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facets visible on https://platform.brevetti.ai/models/ae03ff72-b7a2-444d-8fe9-623f61dc4c71\n",
      "12.295748710632324\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import sys, json\n",
    "# Using sagemaker hyperparameters the TrainingJob instantiates\n",
    "# with settings and dataset access configured by the platform\n",
    "# Job info: NB: replace with ID and api key from your job\n",
    "model_id = os.getenv(\"job_id\") or input(\"Training job model id (can be read from url https://platform.brevetti.ai/models/{model_id})\")\n",
    "api_key = os.getenv(\"api_key\") or getpass.getpass(\"Training job Api Key:\")\n",
    "\n",
    "job = TrainingJob.init(job_id=model_id, api_key=api_key)\n",
    "# The train function optimizes the model and returns a path to the model artifact\n",
    "model = job.train()\n",
    "# The job uploads the model artifact, and closes - don't do this for the tutorial test model, please :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model export\n",
    "NB: this may take 30 s which is deemed too slow for our test pipelines - therefore the code is commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.385178327560425\n"
     ]
    }
   ],
   "source": [
    "# Export model\n",
    "#output_path = job.export(model)\n",
    "\n",
    "# Complete job - which closes the \"connection\" to the job on the platform, and registers the model for deployment\n",
    "# - this may be a test job, so please consider which jobs you close\n",
    "\n",
    "# job.complete_job(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create platform settings file: ```settings_schema.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = TrainingJob.Settings.get_schema().schema\n",
    "json.dump(schema, open(\"settings_schema.json\", \"w\"))\n",
    "\n",
    "# list the output of \"running\" the script above \n",
    "import glob\n",
    "print(\"Listing json files in current directory\")\n",
    "glob.glob('./*.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Zoo: Host training script on [Brevetti AI](https://platform.brevetti.ai)\n",
    "The training script needs to be packaged in a way that the platform can create new training jobs, to produce new model artifacts for the platform user. To set up the training script for the model zoo, use the web interface [BrevettiAI=>Ressources=>Create model type](https://platform.brevetti.ai/resources/modeltypes/create). This lets you\n",
    "* Give the model training script a name\n",
    "* Upload the settings_config.json file\n",
    "* Link to the docker image with the training code - see below how to create this\n",
    "\n",
    "![Create model](https://raw.githubusercontent.com/brevettiai/brevettiai-docs/825b6607ee2de6c0c061f503576842f357377792/src/developers/python-sdk-brevettiai/create_model_type.PNG)\n",
    "![Model zoo](https://raw.githubusercontent.com/brevettiai/brevettiai-docs/825b6607ee2de6c0c061f503576842f357377792/src/developers/python-sdk-brevettiai/model_zoo.PNG)\n",
    "Screen shot of UI for [Create model: platform.brevetti.ai/resources/modeltypes/create](https://platform.brevetti.ai/resources/modeltypes/create) and [Model Zoo: https://platform.brevetti.ai/models/zoo](https://platform.brevetti.ai/models/zoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the script\n",
    "When creating a docker image and script file the following needs to be added to the script, to actually execute the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv.append(\"--serialize_schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def main():\n",
    "    # Run the script with argument --serialize_schema to get a platform settings schema written\n",
    "    if \"--serialize_schema\" in sys.argv:\n",
    "        schema = TrainingJob.Settings.get_schema().schema\n",
    "        json.dump(schema, open(\"settings_schema.json\", \"w\"))\n",
    "    else:\n",
    "        # Using sagemaker hyperparameters the TrainingJob instantiates\n",
    "        # with settings and dataset access configured by the platform\n",
    "        job = TrainingJob.init()\n",
    "        # The train function optimizes the model and returns a path to the model artifact\n",
    "        output_path = job.train()\n",
    "        # The job uploads the model artifact, and closes \n",
    "        job.complete_job(output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # run main module to either serialize settings or run the training\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the training script, the settings schema file can then be created by simply calling the script with the ```--serialize_schema``` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic docker file\n",
    "This Dockerfile sets up an environment with tensorflow and install the required ```brevettiai``` package. Furthermore it sets the entrypoint so it will run using sagemaker called by the Brevetti AI platform.\n",
    "\n",
    "The build script also produces the ```settings_schema.json``` file that is used to create a configurable model for Brevetti AI platform.\n",
    "```\n",
    "FROM tensorflow/tensorflow:2.3.1\n",
    "\n",
    "WORKDIR /brevettiai\n",
    "\n",
    "RUN apt-get update && apt-get install -y git libsm6 libxext6 libxrender-dev\n",
    "\n",
    "COPY image_classifier.py .\n",
    "\n",
    "# Install the required ```brevettiai``` package\n",
    "RUN pip install -U git+https://bitbucket.org/criterionai/core#egg=brevettiai[tf2]\n",
    "\n",
    "# Serializes the settings_schema so it is available in the docker image\n",
    "RUN python3 image_classifier.py --serialize_schema\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"image_classifier.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the docker image and extract the ```settings_schema.json```\n",
    "If you don't have docker installed, this step can be done on https://labs.play-with-docker.com/\n",
    "\n",
    "The python image classifier script and the Dockerfile described in the document, can be found on the documentation github repository [image_classifier.py](https://github.com/brevettiai/brevettiai-docs/blob/master/src/tutorials/image_classifier_101/image_classifier.py) and [Dockerfile](https://github.com/brevettiai/brevettiai-docs/blob/master/src/tutorials/image_classifier_101/Dockerfile)\n",
    "\n",
    "Download the files and run the following lines\n",
    "```\n",
    "docker build -f Dockerfile -t image_classifier.docker.image --stream .\n",
    "```\n",
    "```\n",
    "docker create -ti --name ic_container image_classifier.docker.image\n",
    "docker cp ic_container:/brevettiai/settings_schema.json .\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the docker to a container repository\n",
    "The last step necessary to deploy a docker image is to upload the image to a place that is available to the cloud training job. This can be a public image on [Docker hub](https://dockerhub.io) or a private image hosted by Brevetti AI\n",
    "\n",
    "It is recommnded to tag the image - the following snippets may be used to push to Dockerhub\n",
    "```\n",
    "docker tag $docker_image_name $dockerhub_id/$docker_image_name:$build_number\n",
    "\n",
    "docker login\n",
    "docker push $dockerhub_id/$docker_image_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new \"model type\"\n",
    "With the built docker image, and the ´´´settings_schema.json´´´ file the scene is set to create a new model on the Brevetti AI platform\n",
    "[BrevettiAI=>Ressources=>Create model type](https://platform.brevetti.ai/resources/modeltypes/create).\n",
    "\n",
    "## Create model training job and Test the docker image anywhere\n",
    "On the [Brevetti AI platform](https://platform.brevetti.ai) you can choose Model=>create model to configure a new model training job, by selecting training data and setting the parameters that the ```settings_schema.json``` specify. The training job is run in the cloud when *Start training* button is pushed.\n",
    "\n",
    "The script that is created will runs the model training anywhere, if the *model_id* and *api_key* are provided as command arguments.\n",
    "```\n",
    "docker run --rm --privileged image_classifier.docker.image hwclock -s  --model_id $your_model_id --api_key $your_api_key\n",
    "```\n",
    "NB: these flags hwclock -s --privileged are provided to make the image use the proper clock on windows docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
