{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brevetti_image_tools.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfK3VYYC463l"
      },
      "source": [
        "# Data science tools\n",
        "The brevettiai python package has a series of tools for handling data, and, not least, images. They are described in the following sections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzEXlRHhEavu"
      },
      "source": [
        "# Brevetti AI package installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7MCqSgiEY83"
      },
      "source": [
        "# Install brevettiai using the pip package manager.\n",
        "!pip install -U git+https://bitbucket.org/criterionai/core\n",
        "import brevettiai\n",
        "help(brevettiai)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NqsHQpQqcz-"
      },
      "source": [
        "# Get images from public dataset\n",
        "Load publicly available dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F51CqiLn3j6"
      },
      "source": [
        "use_dataset = \"brevetti_neurips_images\"\n",
        "if use_dataset == \"brevetti_neurips_images\":\n",
        "    dataset_path = \"s3://public.data.criterion.ai/data/NeurIPS_2018_reduced\"\n",
        "elif use_dataset == \"tensorflow_flowers\":\n",
        "    import tensorflow as tf\n",
        "    dataset_path = str(tf.keras.utils.get_file(\n",
        "        'flower_photos',\n",
        "        'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "        untar=True))\n",
        "elif use_dataset == \"tensorflow_datasets_beans\":\n",
        "    import tensorflow_datasets as tfds\n",
        "    batch_size = 4\n",
        "\n",
        "    ds = tfds.load(\"beans\", split=\"test\", shuffle_files=False)\n",
        "\n",
        "    def encode(x):\n",
        "        x[\"encoded\"] = tf.io.encode_png(x[\"image\"])\n",
        "        return x\n",
        "    def map2float(x):\n",
        "        x[\"image\"] = tf.cast(x[\"image\"], tf.float32)\n",
        "        return x\n",
        "    img_ds = ds.map(encode).map(map2float)\n",
        "    imgs = next(iter(img_ds.batch(batch_size).take(1)))\n",
        "    files = []\n",
        "    for ii in range(batch_size):\n",
        "        files.append({\"path\": f\"image_{ii}.png\"})\n",
        "        print(f'Writing file {files[-1][\"path\"]}')\n",
        "        tf.io.write_file(files[-1][\"path\"], img[\"encoded\"][ii])\n",
        "\n",
        "    import pandas as pd\n",
        "    files = pd.DataFrame(files)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XmUjCo4AwT2"
      },
      "source": [
        "# API: Brevetti AI Dataset\n",
        "The dataset object can be used to manage listing of data (and access, if it where not publicly available)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3VLW69RAvs0"
      },
      "source": [
        "from brevettiai.platform.dataset import Dataset\n",
        "ds = Dataset(bucket=dataset_path, resolve_access_rights=False)\n",
        "\n",
        "# Fix to get access to a public bucket without credentials\n",
        "ds.io.minio.client_factory(\"s3://public.data.criterion.ai\", lambda **x:{\"endpoint\": \"s3-eu-west-1.amazonaws.com\"})\n",
        "\n",
        "samples = ds.get_image_samples()\n",
        "# Printing content of a sample from the pandas data frame\n",
        "print(\"Sample: \", samples.sample(1).iloc[0].to_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbP_hWntudRx"
      },
      "source": [
        "Samples now holds the image samples in a pandas dataframe object. We can e.g. investigate the distribution of the different classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp1u0THDuxXB"
      },
      "source": [
        "samples.groupby(\"folder\").count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlJcc3q79AWl"
      },
      "source": [
        "# API: Sample split - sample integrity module\n",
        "## Sample Integrity\n",
        "The brevettiai package uses AWS etags \\(Usually MD5 checksums\\), and file MD5 checksums as method of sample integrity checking. This allows fast listing of identities via the s3 list bucket api for most object, and s3 file metadata storage for the rest.\n",
        "\n",
        "With the MD5 checksums it is possible to alert the user to duplicate samples, and to ensure that duplicates are used for the same purpose \\(training/development/test\\).\n",
        "\n",
        "## Sample split\n",
        "Functionality to split samples between training and **development** sets (often referred to as *validation* set, but this name is confusing in a regulated environment)\n",
        "\n",
        "This module allows for more fine grained control of the splitting process than what is provided by e.g. sklearn.\n",
        "The main feature is that it can split based on *unique* samples rather than just randomly. This is important when multiple images of the same physical item are available\n",
        "* uniqueness\n",
        "* stratification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg6-x_uU9HkF"
      },
      "source": [
        "from brevettiai.data.sample_integrity import SampleSplit\n",
        "from IPython.display import display \n",
        "\n",
        "uniqueness_regex = r\"/(\\d*)_\\d*.bmp\"\n",
        "\n",
        "samples = SampleSplit(stratification=[\"folder\"], uniqueness=uniqueness_regex, split=0.8, seed=42).assign(samples, remainder=\"devel\")\n",
        "print(\"Devel samples\")\n",
        "display(samples[samples[\"purpose\"] == \"devel\"][:5].path.values)\n",
        "print(\"Train samples\")\n",
        "display(samples[samples[\"purpose\"] == \"train\"][:5].path.values)\n",
        "\n",
        "samples.groupby([\"folder\", \"purpose\"]).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO7yLjq5tY8i"
      },
      "source": [
        "# API: Data generator and stratified sampler\n",
        "The brevettiai DataGenerator object is a generator object that extents the functionality of tensorflow datasets by adding\n",
        "* a generated random seed to the map function, so that an image augmentation pipeline may produce reproducible results\n",
        "* the possibility for stratified sampling such that samples can be drawn with controlled freqeuncy from different groups of the dataset\n",
        "\n",
        "the method get_dataset() returns a tensorflow dataset object with the above mentioned properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kZyHKN0-J4F"
      },
      "source": [
        "from brevettiai.data.data_generator import StratifiedSampler, DataGenerator\n",
        "\n",
        "batch_size = 4\n",
        "# creating a data generator with stratification across a grouping on \"folder\" and with a weight determined by the square root of number of samples\n",
        "generator = StratifiedSampler(batch_size=batch_size, groupby=[\"folder\"], group_weighing=\"square root\")\\\n",
        "        .get(samples, shuffle=True, repeat=True, seed=0)\n",
        "\n",
        "for sample in generator.get_dataset().take(2):\n",
        "    print(sample[\"path\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KUN54U1AR2c"
      },
      "source": [
        "The data generator uses stratified sampling across a grouping on \"folder\" and with a weight determined by the square root of number of samples.\n",
        "We can investigate the frequency of samples vs the frequency of actual samples in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHYBEDXoARHc"
      },
      "source": [
        "import pandas as pd\n",
        "from itertools import islice\n",
        "drawn_samples = pd.DataFrame(islice(generator.get_dataset_numpy(batch=False), len(samples)))\n",
        "print(\"Data generator sample frequency\")\n",
        "drawn_samples.groupby(\"folder\").count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FgLxUMUs6Tn"
      },
      "source": [
        "# API: Image pipeline\n",
        "The ImagePipeline object is a utility for\n",
        "* reading a wide range of image formats and adding the reader to the tensorflow dataset graph\n",
        "* (optionally) select region(s) of interest\n",
        "* (optionally) rescale / pad the image to the desired output shape\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Sg5AIxs3Z_"
      },
      "source": [
        "from brevettiai.data.image.image_pipeline import ImagePipeline\n",
        "\n",
        "pipeline = ImagePipeline(target_size=(128, 128))\n",
        "img_generator = generator.map(pipeline)\n",
        "\n",
        "#The image generator now adds the loaded (and reshaped) image to the dataset execution graph, and per default the output is added using the \"img\" key\n",
        "\n",
        "imgs_gen = next(iter(img_generator))\n",
        "# imgs_gen now holds samples with an added image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNuoevdzulkO"
      },
      "source": [
        "# API: Image augmentation\n",
        "Primarily based on the tensorflow augmentation options this api provides an augmentation pipeline that produces repeatable result. It provides two major types of augmentations\n",
        "\n",
        "* transformation augmentation (e.g. flip / rotate / sheare)\n",
        "* image noise augmentation\n",
        "\n",
        "Uses a seed so output is repeatable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aeuk_pKCStiE"
      },
      "source": [
        "from brevettiai.data.image.image_augmenter import ImageAugmenter\n",
        "img_aug = ImageAugmenter()\n",
        "img_generator_aug = img_generator.map(img_aug)\n",
        "imgs_aug = next(iter(img_generator_aug))\n",
        "# The img_generator_aug produces repeatable samples, so taking the first batch a second time, should produce identical output\n",
        "imgs_aug_repeated = next(iter(img_generator_aug))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKWoDDbVMQiy"
      },
      "source": [
        "## Drawing the same sample twice produces the same augmented images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQRbgxzuan5O"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(3, batch_size, figsize=(16, 12))\n",
        "for ii in range(batch_size):\n",
        "    ax[0, ii].imshow(tf.cast(imgs_gen[\"img\"][ii], tf.uint8))\n",
        "    ax[0, ii].set_title(f\"Input image {ii}\")\n",
        "    ax[1, ii].imshow(tf.cast(imgs_aug[\"img\"][ii], tf.uint8))\n",
        "    ax[1, ii].set_title(f\"Augmented image {ii}\")\n",
        "    ax[2, ii].imshow(tf.cast(imgs_aug_repeated[\"img\"][ii], tf.uint8))\n",
        "    ax[2, ii].set_title(f\"Augmented image {ii} repeated\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}