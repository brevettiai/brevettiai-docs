{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brevettiai_job_api_platform_interfaces_documentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "tf2",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqbkhGASC9i6"
      },
      "source": [
        "# Introduction to Brevetti AI Job API\n",
        "brevettiai is a lightweight api for interfacing with the cloud ressources.\n",
        "\n",
        "This notebook documents through examples the simple usage the job api's to access a model training job's artifacts, datasets and lots of other stuff  in a development context\n",
        "\n",
        "This uses the Brevetti AI SDK Job access API\n",
        "\n",
        "* Low level api for models, testreports and development against the platform\n",
        "\n",
        "Job access is granted on instance basis and is tied to the concepts models and test reports on the platform. In Python the job context is managed with the **Job** object\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzEXlRHhEavu"
      },
      "source": [
        "# Brevetti AI package installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7MCqSgiEY83"
      },
      "source": [
        "pip install -U git+https://bitbucket.org/criterionai/core@CORE-22-add-augmentation-to-image-classi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6uIDiTBC9i8"
      },
      "source": [
        "# Imports and setup to avoid extensive verboisty\n",
        "import logging\n",
        "log = logging.getLogger(__name__)\n",
        "logging.basicConfig()\n",
        "log.root.setLevel(logging.DEBUG)\n",
        "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
        "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10HgfgMSC9jS"
      },
      "source": [
        "## BrevettiAI Job API description\n",
        "\n",
        "The Job API is a lower level API. This is the basis of development, model training and test reports. the job api is a set of tools focused around access to your data, tracking of settings and output to the website.\n",
        "\n",
        "This section explores its usage from the perspective of a developer training models on his/her own computer.\n",
        "Except for the initialization of the environment, all of the code is transferrable to a docker containerized deployment of model training on the platform.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SONPspDHcJF4"
      },
      "source": [
        "\n",
        "## Initialization of the development job context\n",
        "\n",
        "A developer access the development context (**CriterionConfig**) of unstarted jobs (models) via the web api.\n",
        "\n",
        "When you have the criterion config object you are ready to build your models, add visualizations to your model page, and persist artifacts.\n",
        "\n",
        "Use `help(CriterionConfig)` to get an overview over available methods.\n",
        "\n",
        "When you are finished with the job/model call upload_job_output() and complete_job() on the config object to finalize the model and enable the comparison tool.\n",
        "\n",
        "```python\n",
        "    config.upload_job_output()\n",
        "    training_config.complete_job(path_to_model_artifact)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3faNHKZdTb0"
      },
      "source": [
        "## Platform Job Interface\n",
        "To access a job you need the model id from e.g. the model path https://platform.brevetti.ai/models/<model_id> and the api key, also accessible from the platform, which together grant you access to the data storage ressources.\n",
        "\n",
        "If you, instead, used the web api to get access to, and start a model, they id and key can be found in the response\n",
        "\n",
        "* model_id = model_def[\"id\"]\n",
        "\n",
        "* api_key = model_def[\"apiKey\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8OEyxxJdTb1"
      },
      "source": [
        "# Job info: NB: replace with ID and api key from your job\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "model_id = os.getenv(\"job_id\") or input(\"Training job model id (can be read from url https://platform.brevetti.ai/models/{model_id})\")\n",
        "api_key = os.getenv(\"api_key\") or getpass.getpass(\"Training job Api Key:\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9prN9dRB8xF"
      },
      "source": [
        "from brevettiai.platform import Job\n",
        "from brevettiai.interfaces import vue_schema_utils\n",
        " \n",
        "job = Job.init(job_id=model_id, api_key=api_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIVg902QC9jW"
      },
      "source": [
        "## Storage\n",
        "\n",
        "In the job context you have two storage modes, temporary and persisted storage. Temporary storage is local on the machine, while the persisted storage is in the cloud in the form of artifacts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLnU5pgYC9jW"
      },
      "source": [
        "temp_path = job.temp_path(\"something_i_want_to_save_temporarily.txt\")\n",
        "print(temp_path)\n",
        "\n",
        "job.io.write_file(temp_path, \"Valuable information\")\n",
        "print(str(job.io.read_file(temp_path), \"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INQ9DqiUC9jZ"
      },
      "source": [
        "artifact_path = job.artifact_path(\"something_i_want_to_save.txt\")\n",
        "print(f\"Available at on the website: {job.host_name}/models/{job.id}/artifacts\")\n",
        "\n",
        "# And in from the job\n",
        "job.io.write_file(artifact_path, \"Valuable information\")\n",
        "print(str(job.io.read_file(artifact_path), \"utf-8\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMDACaI7C9jb"
      },
      "source": [
        "# API: Accessing datasets and downloading samples\n",
        "Samples in a dataset can be accessed via the dataset objects in a platform job object. Access rights are managed seamlessly.\n",
        "\n",
        "Sample integrity and purpose management can be done easily through the sample integrity module, which splits the samples for test and training, taking duplicates, stratification, etc. into account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY60bZkYC9jc"
      },
      "source": [
        "from brevettiai.platform import get_image_samples\n",
        "samples = get_image_samples(job.datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MaZQcXSC9je"
      },
      "source": [
        "from brevettiai.data.sample_integrity import SampleSplit\n",
        "samples = SampleSplit().update_unassigned(samples, id_path=job.artifact_path(\"sample_identification.csv\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFnEZMSgC9ji"
      },
      "source": [
        "samples.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eiInPZ0C9jl"
      },
      "source": [
        "## Loading datasets\n",
        "File operations can be performed via the io_tools object. This object manages access of local and remote resources across windows and linux platforms. along with local cachin of files etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PynKvhvlC9jl"
      },
      "source": [
        "# io_tools is accessible from the job object or directly via import 'from brevettiai.io import io_tools'\n",
        "# Note that access rights are configured on the IoTools object, and as such different instances of the object\n",
        "# does not neccesarily have access to the same files. \n",
        "io_tools = job.io\n",
        "buf = io_tools.read_file(samples.path[0])\n",
        "buf[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFF86hzEC9jo"
      },
      "source": [
        "# Set caching of remote objects globally for all operations on the IoTools object\n",
        "io_tools.set_cache_root(job.temp_path(\"cache\", dir=True))\n",
        "# Or as a key in the read_file method"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt7N_zcNC9jr"
      },
      "source": [
        "## Loading image data with tensorflow datasets\n",
        "Samples may be easily loaded into tensorflow datasets with the **DataGenerator** class. **DataGenerator** contains a lot of functionality out of the box. Among others to sample, shuffle and seed your data generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4gtdCJQC9jr"
      },
      "source": [
        "from brevettiai.data.data_generator import StratifiedSampler, DataGenerator, OneHotEncoder\n",
        "from brevettiai.data.image import ImagePipeline, ImageAugmenter, SegmentationLoader\n",
        "\n",
        "ds = StratifiedSampler().get(samples, shuffle=True, batch_size=8, output_structure=(\"path\", \"folder\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkpoGudDC9ju"
      },
      "source": [
        "The DataGenerator has four methods to iterate over data.\n",
        "\n",
        "First returning tensorflow datasets:\n",
        "\n",
        "* `get_samples()` returning the dataset sampled, but with no mapping\n",
        "* `get_dataset()` returning the dataset sampled and mapped\n",
        "\n",
        "Likewise `get_samples_numpy()` and `get_dataset_numpy()` returning numpy iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZEXdDmMC9jv"
      },
      "source": [
        "# Return Data Geneator as tensorflow dataset objects to loop over samples or \"img\" and \"category\"\n",
        "ds.get_samples(), ds.get_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGcoPP4kC9jy"
      },
      "source": [
        "# Get iterator of numpy objects\n",
        "ds.get_samples_numpy(), ds.get_dataset_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFvyXumBC9j0"
      },
      "source": [
        "As tensorflow datasets, you can map the dataset with functions.\n",
        "Among premade functions are ImagePipeline, ImageAugmenter, OneHotEncoder and AnnotationParser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfvHv-bgC9j1"
      },
      "source": [
        "ds = DataGenerator(samples, shuffle=True, batch_size=8, output_structure=(\"img\", \"onehot\"))\n",
        "ds = ds.map(ImagePipeline(target_size=(64,64), antialias=True, rescale=\"imagenet\")) \\\n",
        "    .map(OneHotEncoder(samples.folder.unique(), output_key=\"onehot\"))\n",
        "\n",
        "# Use the structure change the default structure of the ouput\n",
        "ds.get_dataset(structure=(\"path\", \"img\", \"onehot\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcAoPaDfC9j3"
      },
      "source": [
        "from brevettiai.data.image.utils import tile2d\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use structure=None to access all the dataset elements\n",
        "x = next(ds.get_dataset_numpy(structure=None))\n",
        "plt.imshow(tile2d(x[\"img\"], (2,4))[...,0])\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M6XoHG8C9j5"
      },
      "source": [
        "# Use structure=\"img\" to get just the image\n",
        "x = next(ds.get_dataset_numpy(structure=\"img\"))\n",
        "plt.imshow(tile2d(x, (2,4))[...,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXWPeiCgC9j8"
      },
      "source": [
        "Using `build_image_data_generator` makes a simple dataset, combining loading, augmentation and onehot encoding og categories, and returning an (image, onehot) tuple which may be used directly as input to keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iixs-fnlC9j8"
      },
      "source": [
        "from brevettiai.data.data_generator import build_image_data_generator\n",
        "ds = build_image_data_generator(samples, batch_size=8, image=dict(target_size=(224, 224), antialias=True, rescale=\"imagenet\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoN4w-PeC9j_"
      },
      "source": [
        "The standard modules of TfDataset are deterministic and randomness may be seeded. Thus multiple runs of the same dataset object will result in the same output sequence. By application of the `seed` parameter, this can be true across multiple similar TfDataset objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ngDb9jFC9kA"
      },
      "source": [
        "from brevettiai.data.data_generator import build_image_data_generator\n",
        "ds = build_image_data_generator(samples, batch_size=8, image=dict(target_size=(224, 224), antialias=True, rescale=\"imagenet\"))\n",
        "x = next(ds.get_dataset_numpy())\n",
        "plt.figure()\n",
        "plt.title(\"Run 1\")\n",
        "plt.imshow(tile2d(x[0], (2,4))[...,0])\n",
        "plt.figure()\n",
        "plt.title(\"Run 2 of the same dataset results in the same sampling and augmentation performed on the dataset\")\n",
        "x = next(ds.get_dataset_numpy())\n",
        "plt.imshow(tile2d(x[0], (2,4))[...,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVMUv1DdC9kC"
      },
      "source": [
        "# API: Interfaces / integrations\n",
        "##Job output to platform website\n",
        "A number of different outputs are available on the platform, here is a subset.\n",
        "\n",
        "## Metrics\n",
        "Metrics which may be compared across models can be added via the config object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPgK9gO1C9kD"
      },
      "source": [
        "print(f\"Uploading metrics and outputs to {job.host_name}/models/{model_id}/artifacts\")\n",
        "job.add_output_metric(\"My custom metric\", 277)\n",
        "job.upload_job_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x__gkiUBCkkN"
      },
      "source": [
        "## Progress monitoring (Models only)\n",
        "Add progress metrics to monitor your models while it is running, by adding the RemoteMonitor callback to your keras training loop or call it yourself in your training code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23ZngZ5bCoAL"
      },
      "source": [
        "from brevettiai.interfaces.remote_monitor import RemoteMonitor\n",
        "remote_monitor_callback = RemoteMonitor(root=job.host_name, path=job.api_endpoints[\"remote\"])\n",
        "# Simulate training epochs and produce callbacks\n",
        "remote_monitor_callback.on_epoch_end(11, {\"loss\": 0.9, \"accuracy\": 0.5})\n",
        "remote_monitor_callback.on_epoch_end(12, {\"loss\": 0.7, \"accuracy\": 0.8})\n",
        "\n",
        "print(f\"Training progress visible on {job.host_name}/models/{model_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2_wHC-HC9kH"
      },
      "source": [
        "## Pivot tables\n",
        "\n",
        "create pivot tables on the web platform to get an overview over your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5MJIUH5C9kH"
      },
      "source": [
        "from brevettiai.interfaces.pivot import export_pivot_table, get_default_fields, pivot_fields\n",
        "export_pivot_table(job.artifact_path(\"pivot\", dir=True), samples,\n",
        "                   datasets=job.datasets,\n",
        "                   fields=None,\n",
        "                   tags=job.get_root_tags(),\n",
        "                   rows=[\"dataset_id\"],\n",
        "                   cols=[\"category\"],\n",
        "                   agg={\"url\": \"first\"})\n",
        "print(f\"Pivot table visible on {job.host_name}/models/{model_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBT0_SfPC9kK"
      },
      "source": [
        "## Facets\n",
        "Create facet dives to explore your data in depth by creating a dataset outputting thumbnails of size (64x64) per sample. \n",
        "![Facet example](https://gblobscdn.gitbook.com/assets%2F-LY12YhLSCDWlqNaQqWT%2F-MIdFH6dqJxgrYtQH83E%2F-MIdJ3qn1kPxLh6K0YI0%2Fimage.png?alt=media&token=d59993dc-9dd0-4f97-a548-4d6ceddf257d)\n",
        "\n",
        "Put the files in the facets folder in your artifacts. To use the built-in tools you need to supply a DataGenerator which outputs a 64x64 thumbnail image, and category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7I0XpmMC9kK"
      },
      "source": [
        "from brevettiai.interfaces.facets_atlas import build_facets\n",
        "from brevettiai.data.data_generator import StratifiedSampler, DataGenerator\n",
        "fds = DataGenerator(samples, shuffle=True, output_structure=(\"img\", \"category\")) \\\n",
        "    .map(ImagePipeline(target_size=(64,64), antialias=True))\n",
        "\n",
        "build_facets(fds, job.artifact_path(\"facets\", dir=True), count=32)\n",
        "\n",
        "print(f\"Facets visible on {job.host_name}/models/{model_id}\")\n",
        "\n",
        "build_facets(fds, job.artifact_path(\"facets\", dir=True), count=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKlFaciBkO00"
      },
      "source": [
        "## Vega-lite charts\n",
        "Vega-Lite charts\n",
        "Add Vega-Lite charts to your model page by calling upload_chart on the configuration object. Some different standard charts are available under brevettiai.interfaces.vegalite_charts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QPNxXw1kWy_"
      },
      "source": [
        "from brevettiai.interfaces import vegalite_charts\n",
        "\n",
        "vegalite_json = vegalite_charts.dataset_summary(samples)\n",
        "job.upload_chart(vegalite_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajDPritL9Fti"
      },
      "source": [
        "# Complete job to update the following on the platform\n",
        "* The path to the model file (optional)\n",
        "* That the training or testing process is finished, so the UI can be updated\n",
        "* That access to write to the artifact path, and access to the datasets should no longer be granted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLtLcTkP9CQs"
      },
      "source": [
        "# job.complete_job()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}